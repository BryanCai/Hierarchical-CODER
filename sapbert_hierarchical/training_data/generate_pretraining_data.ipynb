{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import random\n",
    "import csv\n",
    "from random import shuffle\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load MRCONSO.RFF (and some basic preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMLS_DIR = Path(\"C:/Users/bxcai/Downloads/umls-2021AB-metathesaurus/2021AB/META\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16543671\n"
     ]
    }
   ],
   "source": [
    "with open(UMLS_DIR/\"MRCONSO.RRF\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use only English names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73afbe62b514442cb69af816f7aea662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16543671.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11755677\n"
     ]
    }
   ],
   "source": [
    "cleaned = []\n",
    "count = 0\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\"|\")\n",
    "    cui, lang, synonym = lst[0], lst[1], lst[14]\n",
    "    if lang != \"ENG\": continue # comment this out if you need all languages\n",
    "    row = cui+\"||\"+synonym.lower()\n",
    "    cleaned.append(row)\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11755677\n",
      "9580357\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned))\n",
    "cleaned = list(set(cleaned)) \n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add tradeneames (optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regard drug tradenames/brandnames from the relation file as synonym relations. This slightly boosts SapBERT's performance on some biomedical entity linking datasets (e.g. COMETA). MRREL.RRF can be extracted from the full UMLS release file: https://www.nlm.nih.gov/research/umls/licensedcontent/umlsarchives04.html#2020AA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54660298\n"
     ]
    }
   ],
   "source": [
    "# load MRCONSO.RFF\n",
    "with open(UMLS_DIR/\"MRREL.RRF\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0a4d6b903f4ec1be6c541d8b2e750c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9580357.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "umls_dict = {} # constrauct cui to list of name dict\n",
    "for line in tqdm(cleaned):\n",
    "    cui, name = line.split(\"||\")\n",
    "    if cui in umls_dict:\n",
    "        umls_dict[cui].append(name)\n",
    "    else:\n",
    "        umls_dict[cui] = [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250e5a3a241c447eaeb50910d6297c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54660298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "131088\n"
     ]
    }
   ],
   "source": [
    "tradename_mappings = {}\n",
    "for l in tqdm(lines):\n",
    "    if \"has_tradename\" in l or \"tradename_of\" in l:\n",
    "        cells =l.split(\"|\")\n",
    "        head, tail = cells[0], cells[4]\n",
    "        try: # if in CUI\n",
    "            sfs = umls_dict[tail]\n",
    "            tradename_mappings[head] = sfs\n",
    "        except:\n",
    "            continue\n",
    "print(len(tradename_mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9580357\n",
      "10542116\n"
     ]
    }
   ],
   "source": [
    "# add tradenames\n",
    "print(len(cleaned))\n",
    "for cui,synonyms in tradename_mappings.items():\n",
    "    for s in synonyms:\n",
    "        row = cui+\"||\"+ s.lower()\n",
    "        cleaned.append(row)\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplications, again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10542116\n",
      "10541661\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned))\n",
    "cleaned_do_dup = list(set(cleaned))\n",
    "print(len(list(set(cleaned_do_dup))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## positive pairs generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1024583068b646f191590dfef0efd2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10541661.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "umls_dict = {} # constrauct cui to list of name dict, again\n",
    "for line in tqdm(cleaned_do_dup):\n",
    "    cui, name = line.split(\"||\")\n",
    "    if cui in umls_dict:\n",
    "        umls_dict[cui].append(name)\n",
    "    else:\n",
    "        umls_dict[cui] = [name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TREE(object):\n",
    "    def __init__(self, tree_path, map_path):\n",
    "        self.tree_path = tree_path\n",
    "        self.map_path = map_path\n",
    "        self.load()\n",
    "    \n",
    "    def clean(self, term, lower=True, clean_NOS=True, clean_bracket=True, clean_dash=True):\n",
    "        term = \" \" + term + \" \"\n",
    "        if lower:\n",
    "            term = term.lower()\n",
    "        if clean_NOS:\n",
    "            term = term.replace(\" NOS \", \" \").replace(\" nos \", \" \")\n",
    "        if clean_bracket:\n",
    "            term = re.sub(u\"\\\\(.*?\\\\)\", \"\", term)\n",
    "        if clean_dash:\n",
    "            term = term.replace(\"-\", \" \")\n",
    "        term = \" \".join([w for w in term.split() if w])\n",
    "        return term\n",
    "\n",
    "    def load(self):\n",
    "        self.parent = {}\n",
    "        self.children = defaultdict(set)\n",
    "        self.grandchildren = defaultdict(set)\n",
    "        self.text = defaultdict(set)\n",
    "        with open(self.tree_path) as f:\n",
    "            reader = csv.reader(f)\n",
    "            reader.__next__()\n",
    "            for row in reader:\n",
    "                parent = row[0]\n",
    "                current = row[1]\n",
    "                if len(parent) > 0 and len(current) > 0:\n",
    "                    self.parent[current] = parent\n",
    "                    self.children[parent].add(current)\n",
    "\n",
    "        with open(self.map_path) as f:\n",
    "            reader = csv.reader(f)\n",
    "            reader.__next__()\n",
    "            for row in reader:\n",
    "                current = row[0]\n",
    "                text = row[1]\n",
    "                self.text[current].add(self.clean(text))\n",
    "\n",
    "        for current in list(self.children):\n",
    "            for child in self.children[current]:\n",
    "                self.grandchildren[current] = self.grandchildren[current].union(self.children[child])\n",
    "\n",
    "        self.text = self.clean_set_dict(self.text)\n",
    "\n",
    "    def clean_set_dict(self, d):\n",
    "        out = {}\n",
    "        for i in d:\n",
    "            if len(d[i]) > 0:\n",
    "                out[i] = tuple(d[i])\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt\n",
      "loinc\n",
      "phecode\n",
      "rxnorm\n"
     ]
    }
   ],
   "source": [
    "TREE_DIR = Path(\"D:/Projects/CODER/Hierarchical-CODER/data/cleaned/all\")\n",
    "\n",
    "TREE_SUBDIRS = [f for f in TREE_DIR.iterdir() if f.is_dir()]\n",
    "trees = {}\n",
    "for tree_subdir in TREE_SUBDIRS:\n",
    "    print(tree_subdir.name)\n",
    "    trees[tree_subdir.name] = TREE(tree_subdir/\"hierarchy.csv\", tree_subdir/\"code2string.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./phecode_holdout_set.txt', 'w') as f:\n",
    "#     for code in random.sample(list(set([i.split(\".\")[0] for i in trees[\"phecode\"].text.keys()])), 100):\n",
    "#         f.write(\"%s\\n\" % code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVAL_DIR = Path(\"D:/Projects/CODER/deps\")\n",
    "# with open(EVAL_DIR/\"COMPREHENSIVE_CUI_CUI_PAIRS_UMLS2021AB.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     lines = f.readlines()\n",
    "# print(len(lines))\n",
    "\n",
    "# with open('./cui_cui_holdout_set.txt', 'w') as f:\n",
    "#     for line in random.sample(lines[1:], 200000):\n",
    "#         f.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"./cui_cui_holdout_set.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ede4d2f77414382a616e808dec14407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "eval_cuis = []\n",
    "eval_tree_codes = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    eval_cuis.append(lst[0])\n",
    "    eval_cuis.append(lst[2])\n",
    "print(len(eval_cuis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10723\n"
     ]
    }
   ],
   "source": [
    "EVAL_DIR = Path(\"D:/Projects/CODER/deps\")\n",
    "with open(EVAL_DIR/\"DDX_Medscape_UMLS2021ABCUIS_vid_01APR2023.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in lines[1:]:\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    eval_cuis.append(lst[2])\n",
    "    eval_cuis.append(lst[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421444\n",
      "216877\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_cuis))\n",
    "eval_cuis = list(set(eval_cuis)) \n",
    "print(len(eval_cuis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_terms = []\n",
    "for i in eval_cuis:\n",
    "    if i in umls_dict:\n",
    "        eval_terms += umls_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278400\n",
      "1165731\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_terms))\n",
    "eval_terms = list(set(eval_terms)) \n",
    "print(len(eval_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "EVAL_DIR = Path(\"D:/Projects/CODER/Hierarchical-CODER/sapbert_hierarchical/training_data\")\n",
    "with open(EVAL_DIR/\"phecode_holdout_set.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d018cdd86649358eed358bcdfefaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "eval_phecodes = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\")\n",
    "    eval_phecodes.append(lst)\n",
    "print(len(eval_phecodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4536277\n",
      "cpt 14056\n",
      "loinc 171191\n",
      "phecode 1828\n",
      "rxnorm 192683\n"
     ]
    }
   ],
   "source": [
    "print(len(umls_dict))\n",
    "for tree in trees:\n",
    "    print(tree, len(trees[tree].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in eval_cuis:\n",
    "    if i in umls_dict:\n",
    "        del umls_dict[i]\n",
    "\n",
    "all_eval_phecodes = []\n",
    "for phecode in trees[\"phecode\"].text:\n",
    "    if phecode.split(\".\")[0] in eval_phecodes:\n",
    "        all_eval_phecodes.append(phecode)\n",
    "        \n",
    "for phecode in all_eval_phecodes:\n",
    "    if phecode in trees[\"phecode\"].text:\n",
    "        del trees[\"phecode\"].text[phecode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4319404\n",
      "cpt 14056\n",
      "loinc 171191\n",
      "phecode 1506\n",
      "rxnorm 192683\n"
     ]
    }
   ],
   "source": [
    "print(len(umls_dict))\n",
    "for tree in trees:\n",
    "    print(tree, len(trees[tree].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pairs(input_list):\n",
    "    return list(itertools.combinations(input_list, r=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e692a6f9464db0993ff8fe1fa04674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4319404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_pairs = []\n",
    "for k,v in tqdm(umls_dict.items()):\n",
    "    pairs = gen_pairs(v)\n",
    "    if len(pairs)>50: # if >50 pairs, then trim to 50 pairs\n",
    "        pairs = random.sample(pairs, 50)\n",
    "    for p in pairs:\n",
    "        line = str(k) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        pos_pairs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10539693\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C4109392||eulecanium giganteum||eulecanium giganteum (shinji, 1935)',\n",
       " 'C2733947||r cont lens or cylinder||over refraction cylinder:invlen:pt:contact lens.right:qn',\n",
       " 'C2733947||r cont lens or cylinder||right contact lens over refraction cylinder']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_pairs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the pairwise positive training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./training_files/umls.txt', 'w', encoding=\"utf-8\") as f:\n",
    "#     for line in pos_pairs:\n",
    "#         f.write(\"%s\\n\" % line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate RELA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54660298\n"
     ]
    }
   ],
   "source": [
    "# load MRCONSO.RFF\n",
    "with open(UMLS_DIR/\"MRREL.RRF\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87cb9c9abb546b0a03058528618687c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54660298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rela_dict = {}\n",
    "for line in tqdm(lines):\n",
    "    lst = line.split(\"|\")\n",
    "    cui1, rel, cui2, rela = lst[0], lst[3], lst[4], lst[7]\n",
    "    if rela in rela_dict:\n",
    "        rela_dict[rela].append((cui1, cui2))\n",
    "    else:\n",
    "        rela_dict[rela] = [(cui1, cui2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rela_dict:\n",
    "    if len(rela_dict[i]) > 1e5:\n",
    "        rela_dict[i] = random.sample(rela_dict[i], int(1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c9a075c6cb4473b22724df8b27ad92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13456496.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rela_list = [item for i in rela_dict for item in rela_dict[i]]\n",
    "rela_pairs = []\n",
    "for cui1, cui2 in tqdm(rela_list):\n",
    "    if cui1 in umls_dict and cui2 in umls_dict:\n",
    "        pairs = list(itertools.product(umls_dict[cui1], umls_dict[cui2]))\n",
    "        if len(pairs)>5:\n",
    "            pairs = random.sample(pairs, 5)\n",
    "        for p in pairs:\n",
    "            line = min(cui1, cui2) + max(cui1, cui2) + \"||\" + p[0] + \"||\" + p[1]\n",
    "            rela_pairs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14881187\n"
     ]
    }
   ],
   "source": [
    "print(len(rela_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./training_files/umls_rela.txt', 'w', encoding=\"utf-8\") as f:\n",
    "#     for line in rela_pairs:\n",
    "#         f.write(\"%s\\n\" % line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Tree Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_list = []\n",
    "obj_len = 0\n",
    "for tree in trees:\n",
    "    if tree == 'phecode':\n",
    "        obj_list += [(i, tree) for i in trees[tree].text.keys()] * 70\n",
    "        obj_len += len(trees[tree]) * 100\n",
    "    elif tree == 'cpt':\n",
    "        obj_list += [(i, tree) for i in trees[tree].text.keys()] * 10\n",
    "        obj_len += len(trees[tree]) * 15\n",
    "    else:\n",
    "        obj_list += [(i, tree) for i in trees[tree].text.keys()]\n",
    "        obj_len += len(trees[tree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8296b6011e489387a1fc8f327509d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=609854.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 5\n",
    "\n",
    "tree_pairs = {}\n",
    "tree_terms = {}\n",
    "for tree in trees:\n",
    "    tree_pairs[tree] = []\n",
    "    tree_terms[tree] = [i for j in list(trees[tree].text.values()) for i in j]\n",
    "\n",
    "\n",
    "for anchor_id, tree in tqdm(obj_list):\n",
    "\n",
    "    if anchor_id not in trees[tree].text:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    samples = {}\n",
    "    samples_text = {}\n",
    "    for i in range(3):\n",
    "        samples[i] = []\n",
    "        samples_text[i] = []\n",
    "    \n",
    "    \n",
    "\n",
    "    if tree == 'phecode':\n",
    "        if \".\" not in anchor_id:\n",
    "            level = 3\n",
    "        else:\n",
    "            level = 3 - len(anchor_id.split(\".\")[1])\n",
    "            \n",
    "        samples[level - 1] += [i for i in trees[tree].children[anchor_id]]\n",
    "        \n",
    "        if anchor_id in trees[tree].parent:\n",
    "            parent = trees[tree].parent[anchor_id]\n",
    "            samples[level] += [parent]\n",
    "            samples[level] += [i for i in trees[tree].children[parent] if i != anchor_id]\n",
    "        \n",
    "    else:\n",
    "        samples[1] += [i for i in trees[tree].children[anchor_id]]\n",
    "        if anchor_id in trees[tree].parent:\n",
    "            parent = trees[tree].parent[anchor_id]\n",
    "            samples[2] += [parent]\n",
    "            samples[1] += [i for i in trees[tree].children[parent] if i != anchor_id]\n",
    "\n",
    "    samples[0] += [anchor_id]\n",
    "    assert len(samples[0]) == 1\n",
    "\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in samples[i]:\n",
    "            if j in trees[tree].text:\n",
    "                samples_text[i] += trees[tree].text[j]\n",
    "\n",
    "    \n",
    "    for i in samples_text:\n",
    "        if len(samples_text[i]) > 2*MAX_SAMPLES:\n",
    "            samples_text[i] = random.sample(samples_text[i], 2*MAX_SAMPLES)\n",
    "                \n",
    "    \n",
    "    pairs = list(itertools.combinations(samples_text[0], 2))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(0) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        tree_pairs[tree].append(line)    \n",
    "    \n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        pairs = list(itertools.product(samples_text[0], samples_text[i]))\n",
    "        if len(pairs) > MAX_SAMPLES:\n",
    "            pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "        for p in pairs:\n",
    "            line = str(i) + \"||\" + p[0] + \"||\" + p[1]\n",
    "            tree_pairs[tree].append(line)    \n",
    "\n",
    "            \n",
    "    random_samples = random.sample(tree_terms[tree], 2*MAX_SAMPLES)\n",
    "    pairs = list(itertools.product(samples_text[0], random_samples))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(3) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        tree_pairs[tree].append(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt 1219150\n",
      "loinc 1540454\n",
      "phecode 1607130\n",
      "rxnorm 1860910\n"
     ]
    }
   ],
   "source": [
    "for tree in tree_pairs:\n",
    "        print(tree, len(tree_pairs[tree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt 4751900\n",
      "loinc 4948254\n",
      "phecode 5924240\n",
      "rxnorm 5771353\n"
     ]
    }
   ],
   "source": [
    "for tree in tree_pairs:\n",
    "        print(tree, len(tree_pairs[tree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt 1219150\n",
      "loinc 1540454\n",
      "phecode 1394890\n",
      "rxnorm 1860910\n"
     ]
    }
   ],
   "source": [
    "for tree in tree_pairs:\n",
    "    with open('./training_files/' + tree + '.txt', 'w', encoding=\"utf-8\") as f:\n",
    "        for line in tree_pairs[tree]:\n",
    "            f.write(\"%s\\n\" % line)\n",
    "        print(tree, len(tree_pairs[tree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Phecode eval terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt\n",
      "loinc\n",
      "phecode\n",
      "rxnorm\n"
     ]
    }
   ],
   "source": [
    "TREE_DIR = Path(\"D:/Projects/CODER/Hierarchical-CODER/data/cleaned/all\")\n",
    "\n",
    "TREE_SUBDIRS = [f for f in TREE_DIR.iterdir() if f.is_dir()]\n",
    "trees = {}\n",
    "for tree_subdir in TREE_SUBDIRS:\n",
    "    print(tree_subdir.name)\n",
    "    trees[tree_subdir.name] = TREE(tree_subdir/\"hierarchy.csv\", tree_subdir/\"code2string.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "with open('./phecode_holdout_set.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f82eb2a531b43cab09f6bf714b8f83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "eval_tree_codes = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    eval_tree_codes.append(lst[0])\n",
    "\n",
    "all_eval_phecodes = []\n",
    "all_eval_phecodes_text = {}\n",
    "for phecode in trees[\"phecode\"].text:\n",
    "    if phecode.split(\".\")[0] in eval_phecodes:\n",
    "        all_eval_phecodes.append(phecode)\n",
    "        all_eval_phecodes_text[phecode] = trees[\"phecode\"].text[phecode]\n",
    "\n",
    "print(len(all_eval_phecodes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3f353c2b904157ac23396f24d88122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=322.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 5\n",
    "\n",
    "phecode_pairs = []\n",
    "phecode_terms = [i for j in list(all_eval_phecodes_text.values()) for i in j]\n",
    "\n",
    "\n",
    "for anchor_id in tqdm(all_eval_phecodes):\n",
    "\n",
    "    assert anchor_id in all_eval_phecodes_text\n",
    "\n",
    "\n",
    "    samples = {}\n",
    "    samples_text = {}\n",
    "    for i in range(3):\n",
    "        samples[i] = []\n",
    "        samples_text[i] = []\n",
    "    \n",
    "    \n",
    "\n",
    "    if \".\" not in anchor_id:\n",
    "        level = 3\n",
    "    else:\n",
    "        level = 3 - len(anchor_id.split(\".\")[1])\n",
    "\n",
    "    samples[level - 1] += [i for i in trees[\"phecode\"].children[anchor_id]]\n",
    "\n",
    "    if anchor_id in trees[\"phecode\"].parent:\n",
    "        parent = trees[\"phecode\"].parent[anchor_id]\n",
    "        samples[level] += [parent]\n",
    "        samples[level] += [i for i in trees[\"phecode\"].children[parent] if i != anchor_id]\n",
    "        \n",
    "        \n",
    "    samples[0] += [anchor_id]\n",
    "    assert len(samples[0]) == 1\n",
    "\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in samples[i]:\n",
    "            if j in all_eval_phecodes_text:\n",
    "                samples_text[i] += all_eval_phecodes_text[j]\n",
    "\n",
    "    \n",
    "    for i in samples_text:\n",
    "        if len(samples_text[i]) > 2*MAX_SAMPLES:\n",
    "            samples_text[i] = random.sample(samples_text[i], 2*MAX_SAMPLES)\n",
    "                \n",
    "    \n",
    "    pairs = list(itertools.combinations(samples_text[0], 2))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(0) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        phecode_pairs.append(line)    \n",
    "    \n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        pairs = list(itertools.product(samples_text[0], samples_text[i]))\n",
    "        if len(pairs) > MAX_SAMPLES:\n",
    "            pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "        for p in pairs:\n",
    "            line = str(i) + \"||\" + p[0] + \"||\" + p[1]\n",
    "            phecode_pairs.append(line)    \n",
    "\n",
    "            \n",
    "    random_samples = random.sample(phecode_terms, 2*MAX_SAMPLES)\n",
    "    pairs = list(itertools.product(samples_text[0], random_samples))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(3) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        phecode_pairs.append(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4325\n"
     ]
    }
   ],
   "source": [
    "# with open('../../sapbert_hierarchical_eval/data/phecode_eval.txt', 'w', encoding=\"utf-8\") as f:\n",
    "#     for line in phecode_pairs:\n",
    "#         f.write(\"%s\\n\" % line)\n",
    "#     print(len(phecode_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CUI-CUI eval pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e679e8fa3544b499486cfaa2ce170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10541661.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "umls_dict = {} # constrauct cui to list of name dict, again\n",
    "for line in tqdm(cleaned_do_dup):\n",
    "    cui, name = line.split(\"||\")\n",
    "    if cui in umls_dict:\n",
    "        umls_dict[cui].append(name)\n",
    "    else:\n",
    "        umls_dict[cui] = [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "with open('./cui_cui_holdout_set.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1d622971fe4965a4307d177b6154f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cui_pairs = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    cui_pairs.append([lst[0], lst[2], lst[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb9eb4f8d9b4232b22c412c76732a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febf3f559b5641969f574e7f5a6c2b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cui_cui_pairs = {}\n",
    "cui_set = set()\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    if lst[0] in umls_dict and lst[2] in umls_dict:\n",
    "        cui_cui_pairs[lst[3]] = cui_cui_pairs.get(lst[3], []) + [(lst[0], lst[2])]\n",
    "        cui_set.add(lst[0])\n",
    "        cui_set.add(lst[2])\n",
    "\n",
    "        \n",
    "random_cuis = random.choices(list(cui_set), k=2*5000)\n",
    "cui_cui_pairs[\"random\"] = []\n",
    "for i in tqdm(range(5000)):\n",
    "    cui1, cui2 = random_cuis[2*i:2*(i + 1)]\n",
    "    if cui1 != cui2:\n",
    "        cui_cui_pairs[\"random\"].append((cui1, cui2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_cui_pairs[\"ALL_CAUSITIVE\"] = []\n",
    "for i in [\"cause_of\", \"causative_agent_of\", \"induces\"]:\n",
    "    cui_cui_pairs[\"ALL_CAUSITIVE\"] += cui_cui_pairs.get(i, [])\n",
    "\n",
    "cui_cui_pairs[\"ALL_MAY_CAUSE_OR_TREAT\"] = []\n",
    "for i in [\"may_treat\", \"may_prevent\"]:\n",
    "    cui_cui_pairs[\"ALL_MAY_CAUSE_OR_TREAT\"] += cui_cui_pairs.get(i, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_cui_pairs_text = {}\n",
    "for i in cui_cui_pairs:\n",
    "    for cui1, cui2 in cui_cui_pairs[i]:\n",
    "        line = random.choice(umls_dict[cui1]) + \"||\" + random.choice(umls_dict[cui2]) + \"||\" + i\n",
    "        cui_cui_pairs_text[i] = cui_cui_pairs_text.get(i, []) + [line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aaa513a951848c6bf50e8ee7caf4bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10722.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EVAL_DIR = Path(\"D:/Projects/CODER/deps\")\n",
    "with open(EVAL_DIR/\"DDX_Medscape_UMLS2021ABCUIS_vid_01APR2023.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))\n",
    "\n",
    "cui_cui_pairs_text[\"DDX\"] = []\n",
    "\n",
    "for l in tqdm(lines[1:]):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    line = lst[5] + \"||\" + lst[6] + \"||\" + \"DDX\"\n",
    "    cui_cui_pairs_text[\"DDX\"].append(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_relations = []\n",
    "# for i in cui_cui_pairs_text:\n",
    "#     if len(cui_cui_pairs_text[i]) > 1000:\n",
    "#         common_relations.append(i)\n",
    "# common_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = [\"ALL_CAUSITIVE\",\n",
    "            \"ALL_MAY_CAUSE_OR_TREAT\",\n",
    "            \"method_of\",\n",
    "            \"classifies\",\n",
    "            \"DDX\",\n",
    "            \"random\"]\n",
    "for relation in cui_cui_pairs_text:\n",
    "    if relation not in excluded and len(cui_cui_pairs_text[relation]) > 2000:\n",
    "        cui_cui_pairs_text[relation] = random.sample(cui_cui_pairs_text[relation], 2000)\n",
    "\n",
    "cui_cui_pairs_filtered = []\n",
    "\n",
    "for i in cui_cui_pairs_text.values():\n",
    "    cui_cui_pairs_filtered += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110547\n"
     ]
    }
   ],
   "source": [
    "# with open('../../sapbert_hierarchical_eval/data/cui_cui_eval.txt', 'w', encoding=\"utf-8\") as f:\n",
    "#     for line in cui_cui_pairs_filtered:\n",
    "#         f.write(\"%s\\n\" % line)\n",
    "#     print(len(cui_cui_pairs_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "76\n",
      "900\n",
      "5072\n",
      "10722\n",
      "1451\n",
      "2000\n",
      "1350\n",
      "2000\n",
      "2000\n",
      "1239\n",
      "2000\n",
      "1402\n",
      "1260\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "1408\n",
      "2000\n",
      "1268\n",
      "5072\n",
      "1453\n",
      "1393\n",
      "1713\n",
      "1720\n",
      "1493\n",
      "1110\n",
      "2000\n",
      "1156\n"
     ]
    }
   ],
   "source": [
    "x = sorted([(i, len(cui_cui_pairs_text[i])) for i in cui_cui_pairs_text], key = lambda x: x[1], reverse=True)\n",
    "\n",
    "relation_list = [\n",
    "                 'ALL_CAUSITIVE',\n",
    "                 'ALL_MAY_CAUSE_OR_TREAT',\n",
    "                 'method_of',\n",
    "                 'classifies',\n",
    "                 'DDX',\n",
    "                 'component_of',\n",
    "                 'classified_as',\n",
    "                 'finding_site_of',\n",
    "                 'translation_of',\n",
    "                 'isa',\n",
    "                 'subset_includes_concept',\n",
    "                 'inverse_isa',\n",
    "                 'has_ingredient',\n",
    "                 'concept_in_subset',\n",
    "                 'mapped_from',\n",
    "                 'has_member',\n",
    "                 'member_of',\n",
    "                 'has_translation',\n",
    "                 'expanded_form_of',\n",
    "                 'mapped_to',\n",
    "                 'has_inactive_ingredient',\n",
    "                 'ingredient_of',\n",
    "                 'inactive_ingredient_of',\n",
    "                 'has_finding_site',\n",
    "                 'classifies',\n",
    "                 'active_moiety_of',\n",
    "                 'has_component',\n",
    "                 'has_active_ingredient',\n",
    "                 'active_ingredient_of',\n",
    "                 'has_active_moiety',\n",
    "                 'has_class',\n",
    "                 'has_expanded_form',\n",
    "                 'class_of'\n",
    "                 ]\n",
    "\n",
    "\n",
    "for i in relation_list:\n",
    "#     print(\"'\" + i[0] + \"',\")\n",
    "    print(len(cui_cui_pairs_text[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x():\n",
    "    for i in range(4):\n",
    "        yield(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(x())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(a, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-1a2e6ec5f1e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
