{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import random\n",
    "import csv\n",
    "from random import shuffle\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load MRCONSO.RFF (and some basic preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMLS_DIR = Path(\"C:/Users/bxcai/Downloads/umls-2021AB-metathesaurus/2021AB/META\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16543671\n"
     ]
    }
   ],
   "source": [
    "with open(UMLS_DIR/\"MRCONSO.RRF\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use only English names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9198a39a387d4eea92eb286b3daa7ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16543671.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11755677\n"
     ]
    }
   ],
   "source": [
    "cleaned = []\n",
    "count = 0\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\"|\")\n",
    "    cui, lang, synonym = lst[0], lst[1], lst[14]\n",
    "    if lang != \"ENG\": continue # comment this out if you need all languages\n",
    "    row = cui+\"||\"+synonym.lower()\n",
    "    cleaned.append(row)\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11755677\n",
      "9580357\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned))\n",
    "cleaned = list(set(cleaned)) \n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C5049734||macrosiphum sp. bioug09174-g05',\n",
       " 'C5005512||aprostocetus sp. bioug32162-g08',\n",
       " 'C4742770||benzyl pivalate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add tradeneames (optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regard drug tradenames/brandnames from the relation file as synonym relations. This slightly boosts SapBERT's performance on some biomedical entity linking datasets (e.g. COMETA). MRREL.RRF can be extracted from the full UMLS release file: https://www.nlm.nih.gov/research/umls/licensedcontent/umlsarchives04.html#2020AA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54660298\n"
     ]
    }
   ],
   "source": [
    "# load MRCONSO.RFF\n",
    "with open(UMLS_DIR/\"MRREL.RRF\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2b8b6c1f584c928e4fc000755df49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9580357.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "umls_dict = {} # constrauct cui to list of name dict\n",
    "for line in tqdm(cleaned):\n",
    "    cui, name = line.split(\"||\")\n",
    "    if cui in umls_dict:\n",
    "        umls_dict[cui].append(name)\n",
    "    else:\n",
    "        umls_dict[cui] = [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9a9238240f4ad59b3ebc8cfa45c1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54660298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "131088\n"
     ]
    }
   ],
   "source": [
    "tradename_mappings = {}\n",
    "for l in tqdm(lines):\n",
    "    if \"has_tradename\" in l or \"tradename_of\" in l:\n",
    "        cells =l.split(\"|\")\n",
    "        head, tail = cells[0], cells[4]\n",
    "        try: # if in CUI\n",
    "            sfs = umls_dict[tail]\n",
    "            tradename_mappings[head] = sfs\n",
    "        except:\n",
    "            continue\n",
    "print(len(tradename_mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9580357\n",
      "10542116\n"
     ]
    }
   ],
   "source": [
    "# add tradenames\n",
    "print(len(cleaned))\n",
    "for cui,synonyms in tradename_mappings.items():\n",
    "    for s in synonyms:\n",
    "        row = cui+\"||\"+ s.lower()\n",
    "        cleaned.append(row)\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplications, again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10542116\n",
      "10541661\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned))\n",
    "cleaned_do_dup = list(set(cleaned))\n",
    "print(len(list(set(cleaned_do_dup))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## positive pairs generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad675b544c9f409c8864a54068793f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10541661.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "umls_dict = {} # constrauct cui to list of name dict, again\n",
    "for line in tqdm(cleaned_do_dup):\n",
    "    cui, name = line.split(\"||\")\n",
    "    if cui in umls_dict:\n",
    "        umls_dict[cui].append(name)\n",
    "    else:\n",
    "        umls_dict[cui] = [name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TREE(object):\n",
    "    def __init__(self, tree_path, map_path):\n",
    "        self.tree_path = tree_path\n",
    "        self.map_path = map_path\n",
    "        self.load()\n",
    "    \n",
    "    def clean(self, term, lower=True, clean_NOS=True, clean_bracket=True, clean_dash=True):\n",
    "        term = \" \" + term + \" \"\n",
    "        if lower:\n",
    "            term = term.lower()\n",
    "        if clean_NOS:\n",
    "            term = term.replace(\" NOS \", \" \").replace(\" nos \", \" \")\n",
    "        if clean_bracket:\n",
    "            term = re.sub(u\"\\\\(.*?\\\\)\", \"\", term)\n",
    "        if clean_dash:\n",
    "            term = term.replace(\"-\", \" \")\n",
    "        term = \" \".join([w for w in term.split() if w])\n",
    "        return term\n",
    "\n",
    "    def load(self):\n",
    "        self.parent = {}\n",
    "        self.children = defaultdict(set)\n",
    "        self.grandchildren = defaultdict(set)\n",
    "        self.text = defaultdict(set)\n",
    "        with open(self.tree_path) as f:\n",
    "            reader = csv.reader(f)\n",
    "            reader.__next__()\n",
    "            for row in reader:\n",
    "                parent = row[0]\n",
    "                current = row[1]\n",
    "                if len(parent) > 0 and len(current) > 0:\n",
    "                    self.parent[current] = parent\n",
    "                    self.children[parent].add(current)\n",
    "\n",
    "        with open(self.map_path) as f:\n",
    "            reader = csv.reader(f)\n",
    "            reader.__next__()\n",
    "            for row in reader:\n",
    "                current = row[0]\n",
    "                text = row[1]\n",
    "                self.text[current].add(self.clean(text))\n",
    "\n",
    "        for current in list(self.children):\n",
    "            for child in self.children[current]:\n",
    "                self.grandchildren[current] = self.grandchildren[current].union(self.children[child])\n",
    "\n",
    "        self.text = self.clean_set_dict(self.text)\n",
    "\n",
    "    def clean_set_dict(self, d):\n",
    "        out = {}\n",
    "        for i in d:\n",
    "            if len(d[i]) > 0:\n",
    "                out[i] = tuple(d[i])\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt\n",
      "loinc\n",
      "phecode\n",
      "rxnorm\n"
     ]
    }
   ],
   "source": [
    "TREE_DIR = Path(\"D:/Projects/CODER/Hierarchical-CODER/data/cleaned/all\")\n",
    "\n",
    "TREE_SUBDIRS = [f for f in TREE_DIR.iterdir() if f.is_dir()]\n",
    "trees = {}\n",
    "for tree_subdir in TREE_SUBDIRS:\n",
    "    print(tree_subdir.name)\n",
    "    trees[tree_subdir.name] = TREE(tree_subdir/\"hierarchy.csv\", tree_subdir/\"code2string.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./phecode_eval.txt', 'w') as f:\n",
    "#     for code in random.sample(list(set([i.split(\".\")[0] for i in trees[\"phecode\"].text.keys()])), 100):\n",
    "#         f.write(\"%s\\n\" % code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVAL_DIR = Path(\"D:/Projects/CODER/deps\")\n",
    "# with open(EVAL_DIR/\"COMPREHENSIVE_CUI_CUI_PAIRS_UMLS2021AB.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     lines = f.readlines()\n",
    "# print(len(lines))\n",
    "\n",
    "# with open('./cui_cui_pairs_eval.txt', 'w') as f:\n",
    "#     for line in random.sample(lines[1:], 200000):\n",
    "#         f.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"./cui_cui_pairs_eval.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45945a17a6994f04a9abfef4e2690753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "eval_cuis = []\n",
    "eval_tree_codes = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    eval_cuis.append(lst[0])\n",
    "    eval_cuis.append(lst[2])\n",
    "print(len(eval_cuis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "216245\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_cuis))\n",
    "eval_cuis = list(set(eval_cuis)) \n",
    "print(len(eval_cuis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_terms = []\n",
    "for i in eval_cuis:\n",
    "    if i in umls_dict:\n",
    "        eval_terms += umls_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272625\n",
      "1160287\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_terms))\n",
    "eval_terms = list(set(eval_terms)) \n",
    "print(len(eval_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "EVAL_DIR = Path(\"D:/Projects/CODER/Hierarchical-CODER/sapbert_hierarchical/training_data\")\n",
    "with open(EVAL_DIR/\"phecode_eval.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189a3a320caa46d6a4fd0b0af52a854f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "eval_phecodes = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\")\n",
    "    eval_phecodes.append(lst)\n",
    "print(len(eval_phecodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4536277\n",
      "cpt 14056\n",
      "loinc 171191\n",
      "phecode 1828\n",
      "rxnorm 192683\n"
     ]
    }
   ],
   "source": [
    "print(len(umls_dict))\n",
    "for tree in trees:\n",
    "    print(tree, len(trees[tree].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in eval_cuis:\n",
    "    if i in umls_dict:\n",
    "        del umls_dict[i]\n",
    "\n",
    "all_eval_phecodes = []\n",
    "for phecode in trees[\"phecode\"].text:\n",
    "    if phecode.split(\".\")[0] in eval_phecodes:\n",
    "        all_eval_phecodes.append(phecode)\n",
    "        \n",
    "for phecode in all_eval_phecodes:\n",
    "    if phecode in trees[\"phecode\"].text:\n",
    "        del trees[\"phecode\"].text[phecode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320036\n",
      "cpt 14056\n",
      "loinc 171191\n",
      "phecode 1506\n",
      "rxnorm 192683\n"
     ]
    }
   ],
   "source": [
    "print(len(umls_dict))\n",
    "for tree in trees:\n",
    "    print(tree, len(trees[tree].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pairs(input_list):\n",
    "    return list(itertools.combinations(input_list, r=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3508ae63de314db1af42b1db00f97832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4320036.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_pairs = []\n",
    "for k,v in tqdm(umls_dict.items()):\n",
    "    pairs = gen_pairs(v)\n",
    "    if len(pairs)>50: # if >50 pairs, then trim to 50 pairs\n",
    "        pairs = random.sample(pairs, 50)\n",
    "    for p in pairs:\n",
    "        line = str(k) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        pos_pairs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10555030\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C0469458||hollister karaya-5 16\"length 1\"/3272 transparent ileostomy bags x30||hollister 3272 ileobags x30',\n",
       " 'C0469458||hollister karaya-5 16\"length 1\"/3272 transparent ileostomy bags x30||hollister karaya-5 16\"lngth 1\"/3272 trans ileo bags x30',\n",
       " 'C0469458||hollister 3272 ileobags x30||hollister karaya-5 16\"lngth 1\"/3272 trans ileo bags x30']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_pairs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the pairwise positive training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./training_files/umls.txt', 'w', encoding=\"utf-8\") as f:\n",
    "#     for line in pos_pairs:\n",
    "#         f.write(\"%s\\n\" % line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Tree Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_list = []\n",
    "obj_len = 0\n",
    "for tree in trees:\n",
    "    if tree == 'phecode':\n",
    "        obj_list += [(i, tree) for i in trees[tree].text.keys()] * 70\n",
    "        obj_len += len(trees[tree]) * 100\n",
    "    elif tree == 'cpt':\n",
    "        obj_list += [(i, tree) for i in trees[tree].text.keys()] * 10\n",
    "        obj_len += len(trees[tree]) * 15\n",
    "    else:\n",
    "        obj_list += [(i, tree) for i in trees[tree].text.keys()]\n",
    "        obj_len += len(trees[tree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8296b6011e489387a1fc8f327509d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=609854.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 5\n",
    "\n",
    "tree_pairs = {}\n",
    "tree_terms = {}\n",
    "for tree in trees:\n",
    "    tree_pairs[tree] = []\n",
    "    tree_terms[tree] = [i for j in list(trees[tree].text.values()) for i in j]\n",
    "\n",
    "\n",
    "for anchor_id, tree in tqdm(obj_list):\n",
    "\n",
    "    if anchor_id not in trees[tree].text:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    samples = {}\n",
    "    samples_text = {}\n",
    "    for i in range(3):\n",
    "        samples[i] = []\n",
    "        samples_text[i] = []\n",
    "    \n",
    "    \n",
    "\n",
    "    if tree == 'phecode':\n",
    "        if \".\" not in anchor_id:\n",
    "            level = 3\n",
    "        else:\n",
    "            level = 3 - len(anchor_id.split(\".\")[1])\n",
    "            \n",
    "        samples[level - 1] += [i for i in trees[tree].children[anchor_id]]\n",
    "        \n",
    "        if anchor_id in trees[tree].parent:\n",
    "            parent = trees[tree].parent[anchor_id]\n",
    "            samples[level] += [parent]\n",
    "            samples[level] += [i for i in trees[tree].children[parent] if i != anchor_id]\n",
    "        \n",
    "    else:\n",
    "        samples[1] += [i for i in trees[tree].children[anchor_id]]\n",
    "        if anchor_id in trees[tree].parent:\n",
    "            parent = trees[tree].parent[anchor_id]\n",
    "            samples[2] += [parent]\n",
    "            samples[1] += [i for i in trees[tree].children[parent] if i != anchor_id]\n",
    "\n",
    "    samples[0] += [anchor_id]\n",
    "    assert len(samples[0]) == 1\n",
    "\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in samples[i]:\n",
    "            if j in trees[tree].text:\n",
    "                samples_text[i] += trees[tree].text[j]\n",
    "\n",
    "    \n",
    "    for i in samples_text:\n",
    "        if len(samples_text[i]) > 2*MAX_SAMPLES:\n",
    "            samples_text[i] = random.sample(samples_text[i], 2*MAX_SAMPLES)\n",
    "                \n",
    "    \n",
    "    pairs = list(itertools.combinations(samples_text[0], 2))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(0) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        tree_pairs[tree].append(line)    \n",
    "    \n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        pairs = list(itertools.product(samples_text[0], samples_text[i]))\n",
    "        if len(pairs) > MAX_SAMPLES:\n",
    "            pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "        for p in pairs:\n",
    "            line = str(i) + \"||\" + p[0] + \"||\" + p[1]\n",
    "            tree_pairs[tree].append(line)    \n",
    "\n",
    "            \n",
    "    random_samples = random.sample(tree_terms[tree], 2*MAX_SAMPLES)\n",
    "    pairs = list(itertools.product(samples_text[0], random_samples))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(3) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        tree_pairs[tree].append(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt 1219150\n",
      "loinc 1540454\n",
      "phecode 1607130\n",
      "rxnorm 1860910\n"
     ]
    }
   ],
   "source": [
    "for tree in tree_pairs:\n",
    "        print(tree, len(tree_pairs[tree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt 4751900\n",
      "loinc 4948254\n",
      "phecode 5924240\n",
      "rxnorm 5771353\n"
     ]
    }
   ],
   "source": [
    "for tree in tree_pairs:\n",
    "        print(tree, len(tree_pairs[tree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt 1219150\n",
      "loinc 1540454\n",
      "phecode 1394890\n",
      "rxnorm 1860910\n"
     ]
    }
   ],
   "source": [
    "for tree in tree_pairs:\n",
    "    with open('./training_files/' + tree + '.txt', 'w', encoding=\"utf-8\") as f:\n",
    "        for line in tree_pairs[tree]:\n",
    "            f.write(\"%s\\n\" % line)\n",
    "        print(tree, len(tree_pairs[tree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Phecode eval terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt\n",
      "loinc\n",
      "phecode\n",
      "rxnorm\n"
     ]
    }
   ],
   "source": [
    "TREE_DIR = Path(\"D:/Projects/CODER/Hierarchical-CODER/data/cleaned/all\")\n",
    "\n",
    "TREE_SUBDIRS = [f for f in TREE_DIR.iterdir() if f.is_dir()]\n",
    "trees = {}\n",
    "for tree_subdir in TREE_SUBDIRS:\n",
    "    print(tree_subdir.name)\n",
    "    trees[tree_subdir.name] = TREE(tree_subdir/\"hierarchy.csv\", tree_subdir/\"code2string.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "with open('./phecode_eval.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f82eb2a531b43cab09f6bf714b8f83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "eval_tree_codes = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    eval_tree_codes.append(lst[0])\n",
    "\n",
    "all_eval_phecodes = []\n",
    "all_eval_phecodes_text = {}\n",
    "for phecode in trees[\"phecode\"].text:\n",
    "    if phecode.split(\".\")[0] in eval_phecodes:\n",
    "        all_eval_phecodes.append(phecode)\n",
    "        all_eval_phecodes_text[phecode] = trees[\"phecode\"].text[phecode]\n",
    "\n",
    "print(len(all_eval_phecodes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3f353c2b904157ac23396f24d88122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=322.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 5\n",
    "\n",
    "phecode_pairs = []\n",
    "phecode_terms = [i for j in list(all_eval_phecodes_text.values()) for i in j]\n",
    "\n",
    "\n",
    "for anchor_id in tqdm(all_eval_phecodes):\n",
    "\n",
    "    assert anchor_id in all_eval_phecodes_text\n",
    "\n",
    "\n",
    "    samples = {}\n",
    "    samples_text = {}\n",
    "    for i in range(3):\n",
    "        samples[i] = []\n",
    "        samples_text[i] = []\n",
    "    \n",
    "    \n",
    "\n",
    "    if \".\" not in anchor_id:\n",
    "        level = 3\n",
    "    else:\n",
    "        level = 3 - len(anchor_id.split(\".\")[1])\n",
    "\n",
    "    samples[level - 1] += [i for i in trees[\"phecode\"].children[anchor_id]]\n",
    "\n",
    "    if anchor_id in trees[\"phecode\"].parent:\n",
    "        parent = trees[\"phecode\"].parent[anchor_id]\n",
    "        samples[level] += [parent]\n",
    "        samples[level] += [i for i in trees[\"phecode\"].children[parent] if i != anchor_id]\n",
    "        \n",
    "        \n",
    "    samples[0] += [anchor_id]\n",
    "    assert len(samples[0]) == 1\n",
    "\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in samples[i]:\n",
    "            if j in all_eval_phecodes_text:\n",
    "                samples_text[i] += all_eval_phecodes_text[j]\n",
    "\n",
    "    \n",
    "    for i in samples_text:\n",
    "        if len(samples_text[i]) > 2*MAX_SAMPLES:\n",
    "            samples_text[i] = random.sample(samples_text[i], 2*MAX_SAMPLES)\n",
    "                \n",
    "    \n",
    "    pairs = list(itertools.combinations(samples_text[0], 2))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(0) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        phecode_pairs.append(line)    \n",
    "    \n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        pairs = list(itertools.product(samples_text[0], samples_text[i]))\n",
    "        if len(pairs) > MAX_SAMPLES:\n",
    "            pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "        for p in pairs:\n",
    "            line = str(i) + \"||\" + p[0] + \"||\" + p[1]\n",
    "            phecode_pairs.append(line)    \n",
    "\n",
    "            \n",
    "    random_samples = random.sample(phecode_terms, 2*MAX_SAMPLES)\n",
    "    pairs = list(itertools.product(samples_text[0], random_samples))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(3) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        phecode_pairs.append(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4325\n"
     ]
    }
   ],
   "source": [
    "with open('../../sapbert_hierarchical_eval/data/phecode_eval.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for line in phecode_pairs:\n",
    "        f.write(\"%s\\n\" % line)\n",
    "    print(len(phecode_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 354, '2': 1180, '3': 1610, '0': 1181})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([i.split('||')[0] for i in phecode_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../sapbert_hierarchical_eval/data/phecode_eval.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "eval_data = []\n",
    "for l in lines:\n",
    "    lst = l.rstrip(\"\\n\").split(\"||\")\n",
    "    eval_data.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>term1</th>\n",
       "      <th>term2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>salmonella osteomyelitis</td>\n",
       "      <td>acute osteomyelitis involving ankle and foot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>salmonella osteomyelitis</td>\n",
       "      <td>acute osteomyelitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>salmonella osteomyelitis</td>\n",
       "      <td>unspecified osteomyelitis involving hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>salmonella osteomyelitis</td>\n",
       "      <td>acute osteomyelitis involving multiple sites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>salmonella osteomyelitis</td>\n",
       "      <td>acute osteomyelitis involving hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>3</td>\n",
       "      <td>presence of cardiac and vascular implant and g...</td>\n",
       "      <td>other obstetrical trauma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>3</td>\n",
       "      <td>fitting and adjustment of other cardiac device</td>\n",
       "      <td>other obstetrical trauma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>3</td>\n",
       "      <td>unspecified cardiac device in situ</td>\n",
       "      <td>arthrosis, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>3</td>\n",
       "      <td>presence of cardiac and vascular implant and g...</td>\n",
       "      <td>heterophyiasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>3</td>\n",
       "      <td>unspecified cardiac device in situ</td>\n",
       "      <td>closed fracture of base of skull with intracra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4325 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dist                                              term1  \\\n",
       "0       1                           salmonella osteomyelitis   \n",
       "1       1                           salmonella osteomyelitis   \n",
       "2       1                           salmonella osteomyelitis   \n",
       "3       1                           salmonella osteomyelitis   \n",
       "4       1                           salmonella osteomyelitis   \n",
       "...   ...                                                ...   \n",
       "4320    3  presence of cardiac and vascular implant and g...   \n",
       "4321    3     fitting and adjustment of other cardiac device   \n",
       "4322    3                 unspecified cardiac device in situ   \n",
       "4323    3  presence of cardiac and vascular implant and g...   \n",
       "4324    3                 unspecified cardiac device in situ   \n",
       "\n",
       "                                                  term2  \n",
       "0          acute osteomyelitis involving ankle and foot  \n",
       "1                                   acute osteomyelitis  \n",
       "2              unspecified osteomyelitis involving hand  \n",
       "3          acute osteomyelitis involving multiple sites  \n",
       "4                    acute osteomyelitis involving hand  \n",
       "...                                                 ...  \n",
       "4320                           other obstetrical trauma  \n",
       "4321                           other obstetrical trauma  \n",
       "4322                             arthrosis, unspecified  \n",
       "4323                                     heterophyiasis  \n",
       "4324  closed fracture of base of skull with intracra...  \n",
       "\n",
       "[4325 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(eval_data, columns=[\"dist\", \"term1\", \"term2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
