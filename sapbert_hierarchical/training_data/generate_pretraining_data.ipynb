{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import random\n",
    "import csv\n",
    "from random import shuffle\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load MRCONSO.RFF (and some basic preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMLS_DIR = Path(\"C:/Users/bxcai/Downloads/umls-2021AB-metathesaurus/2021AB/META\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16543671\n"
     ]
    }
   ],
   "source": [
    "with open(UMLS_DIR/\"MRCONSO.RRF\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use only English names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6294be4385b346ccbabf4d84e802d2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16543671.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11755677\n"
     ]
    }
   ],
   "source": [
    "cleaned = []\n",
    "count = 0\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\"|\")\n",
    "    cui, lang, synonym = lst[0], lst[1], lst[14]\n",
    "    if lang != \"ENG\": continue # comment this out if you need all languages\n",
    "    row = cui+\"||\"+synonym.lower()\n",
    "    cleaned.append(row)\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11755677\n",
      "9580357\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned))\n",
    "cleaned = list(set(cleaned)) \n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C0226611||structure of superior ophthalmic vein (body structure)',\n",
       " 'C1282958||colitis idiopathic',\n",
       " 'C2504141||medical and surgical @ heart and great vessels @ repair @ pulmonary artery, left @ open @ no device']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add tradeneames (optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regard drug tradenames/brandnames from the relation file as synonym relations. This slightly boosts SapBERT's performance on some biomedical entity linking datasets (e.g. COMETA). MRREL.RRF can be extracted from the full UMLS release file: https://www.nlm.nih.gov/research/umls/licensedcontent/umlsarchives04.html#2020AA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54660298\n"
     ]
    }
   ],
   "source": [
    "# load MRCONSO.RFF\n",
    "with open(UMLS_DIR/\"MRREL.RRF\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e1a3a27dc47d0b2d7221c5f0cafb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9580357.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "umls_dict = {} # constrauct cui to list of name dict\n",
    "for line in tqdm(cleaned):\n",
    "    cui, name = line.split(\"||\")\n",
    "    if cui in umls_dict:\n",
    "        umls_dict[cui].append(name)\n",
    "    else:\n",
    "        umls_dict[cui] = [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc8c4a366934eb2a7586ac8ce25274d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54660298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "131088\n"
     ]
    }
   ],
   "source": [
    "tradename_mappings = {}\n",
    "for l in tqdm(lines):\n",
    "    if \"has_tradename\" in l or \"tradename_of\" in l:\n",
    "        cells =l.split(\"|\")\n",
    "        head, tail = cells[0], cells[4]\n",
    "        try: # if in CUI\n",
    "            sfs = umls_dict[tail]\n",
    "            tradename_mappings[head] = sfs\n",
    "        except:\n",
    "            continue\n",
    "print(len(tradename_mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9580357\n",
      "10542116\n"
     ]
    }
   ],
   "source": [
    "# add tradenames\n",
    "print(len(cleaned))\n",
    "for cui,synonyms in tradename_mappings.items():\n",
    "    for s in synonyms:\n",
    "        row = cui+\"||\"+ s.lower()\n",
    "        cleaned.append(row)\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplications, again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10542116\n",
      "10541661\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned))\n",
    "cleaned_do_dup = list(set(cleaned))\n",
    "print(len(list(set(cleaned_do_dup))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## positive pairs generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9445a0a04a4db5b5d65635be7962ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10541661.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "umls_dict = {} # constrauct cui to list of name dict, again\n",
    "for line in tqdm(cleaned_do_dup):\n",
    "    cui, name = line.split(\"||\")\n",
    "    if cui in umls_dict:\n",
    "        umls_dict[cui].append(name)\n",
    "    else:\n",
    "        umls_dict[cui] = [name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TREE(object):\n",
    "    def __init__(self, tree_path, map_path):\n",
    "        self.tree_path = tree_path\n",
    "        self.map_path = map_path\n",
    "        self.load()\n",
    "    \n",
    "    def clean(self, term, lower=True, clean_NOS=True, clean_bracket=True, clean_dash=True):\n",
    "        term = \" \" + term + \" \"\n",
    "        if lower:\n",
    "            term = term.lower()\n",
    "        if clean_NOS:\n",
    "            term = term.replace(\" NOS \", \" \").replace(\" nos \", \" \")\n",
    "        if clean_bracket:\n",
    "            term = re.sub(u\"\\\\(.*?\\\\)\", \"\", term)\n",
    "        if clean_dash:\n",
    "            term = term.replace(\"-\", \" \")\n",
    "        term = \" \".join([w for w in term.split() if w])\n",
    "        return term\n",
    "\n",
    "    def load(self):\n",
    "        self.parent = {}\n",
    "        self.children = defaultdict(set)\n",
    "        self.grandchildren = defaultdict(set)\n",
    "        self.text = defaultdict(set)\n",
    "        with open(self.tree_path) as f:\n",
    "            reader = csv.reader(f)\n",
    "            reader.__next__()\n",
    "            for row in reader:\n",
    "                parent = row[0]\n",
    "                current = row[1]\n",
    "                if len(parent) > 0 and len(current) > 0:\n",
    "                    self.parent[current] = parent\n",
    "                    self.children[parent].add(current)\n",
    "\n",
    "        with open(self.map_path) as f:\n",
    "            reader = csv.reader(f)\n",
    "            reader.__next__()\n",
    "            for row in reader:\n",
    "                current = row[0]\n",
    "                text = row[1]\n",
    "                self.text[current].add(self.clean(text))\n",
    "\n",
    "        for current in list(self.children):\n",
    "            for child in self.children[current]:\n",
    "                self.grandchildren[current] = self.grandchildren[current].union(self.children[child])\n",
    "\n",
    "        self.text = self.clean_set_dict(self.text)\n",
    "\n",
    "    def clean_set_dict(self, d):\n",
    "        out = {}\n",
    "        for i in d:\n",
    "            if len(d[i]) > 0:\n",
    "                out[i] = tuple(d[i])\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt\n",
      "loinc\n",
      "phecode\n",
      "rxnorm\n"
     ]
    }
   ],
   "source": [
    "TREE_DIR = Path(\"D:/Projects/CODER/Hierarchical-CODER/data/cleaned/all\")\n",
    "\n",
    "TREE_SUBDIRS = [f for f in TREE_DIR.iterdir() if f.is_dir()]\n",
    "trees = {}\n",
    "for tree_subdir in TREE_SUBDIRS:\n",
    "    print(tree_subdir.name)\n",
    "    trees[tree_subdir.name] = TREE(tree_subdir/\"hierarchy.csv\", tree_subdir/\"code2string.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./phecode_holdout_set.txt', 'w') as f:\n",
    "#     for code in random.sample(list(set([i.split(\".\")[0] for i in trees[\"phecode\"].text.keys()])), 100):\n",
    "#         f.write(\"%s\\n\" % code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVAL_DIR = Path(\"D:/Projects/CODER/deps\")\n",
    "# with open(EVAL_DIR/\"COMPREHENSIVE_CUI_CUI_PAIRS_UMLS2021AB.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     lines = f.readlines()\n",
    "# print(len(lines))\n",
    "\n",
    "# with open('./cui_cui_holdout_set.txt', 'w') as f:\n",
    "#     for line in random.sample(lines[1:], 200000):\n",
    "#         f.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"./cui_cui_holdout_set.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45945a17a6994f04a9abfef4e2690753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "eval_cuis = []\n",
    "eval_tree_codes = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    eval_cuis.append(lst[0])\n",
    "    eval_cuis.append(lst[2])\n",
    "print(len(eval_cuis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "216245\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_cuis))\n",
    "eval_cuis = list(set(eval_cuis)) \n",
    "print(len(eval_cuis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_terms = []\n",
    "for i in eval_cuis:\n",
    "    if i in umls_dict:\n",
    "        eval_terms += umls_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272625\n",
      "1160287\n"
     ]
    }
   ],
   "source": [
    "print(len(eval_terms))\n",
    "eval_terms = list(set(eval_terms)) \n",
    "print(len(eval_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "EVAL_DIR = Path(\"D:/Projects/CODER/Hierarchical-CODER/sapbert_hierarchical/training_data\")\n",
    "with open(EVAL_DIR/\"phecode_holdout_set.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189a3a320caa46d6a4fd0b0af52a854f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "eval_phecodes = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\")\n",
    "    eval_phecodes.append(lst)\n",
    "print(len(eval_phecodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4536277\n",
      "cpt 14056\n",
      "loinc 171191\n",
      "phecode 1828\n",
      "rxnorm 192683\n"
     ]
    }
   ],
   "source": [
    "print(len(umls_dict))\n",
    "for tree in trees:\n",
    "    print(tree, len(trees[tree].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in eval_cuis:\n",
    "    if i in umls_dict:\n",
    "        del umls_dict[i]\n",
    "\n",
    "all_eval_phecodes = []\n",
    "for phecode in trees[\"phecode\"].text:\n",
    "    if phecode.split(\".\")[0] in eval_phecodes:\n",
    "        all_eval_phecodes.append(phecode)\n",
    "        \n",
    "for phecode in all_eval_phecodes:\n",
    "    if phecode in trees[\"phecode\"].text:\n",
    "        del trees[\"phecode\"].text[phecode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320036\n",
      "cpt 14056\n",
      "loinc 171191\n",
      "phecode 1506\n",
      "rxnorm 192683\n"
     ]
    }
   ],
   "source": [
    "print(len(umls_dict))\n",
    "for tree in trees:\n",
    "    print(tree, len(trees[tree].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pairs(input_list):\n",
    "    return list(itertools.combinations(input_list, r=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3508ae63de314db1af42b1db00f97832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4320036.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_pairs = []\n",
    "for k,v in tqdm(umls_dict.items()):\n",
    "    pairs = gen_pairs(v)\n",
    "    if len(pairs)>50: # if >50 pairs, then trim to 50 pairs\n",
    "        pairs = random.sample(pairs, 50)\n",
    "    for p in pairs:\n",
    "        line = str(k) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        pos_pairs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10555030\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C0469458||hollister karaya-5 16\"length 1\"/3272 transparent ileostomy bags x30||hollister 3272 ileobags x30',\n",
       " 'C0469458||hollister karaya-5 16\"length 1\"/3272 transparent ileostomy bags x30||hollister karaya-5 16\"lngth 1\"/3272 trans ileo bags x30',\n",
       " 'C0469458||hollister 3272 ileobags x30||hollister karaya-5 16\"lngth 1\"/3272 trans ileo bags x30']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_pairs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the pairwise positive training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./training_files/umls.txt', 'w', encoding=\"utf-8\") as f:\n",
    "#     for line in pos_pairs:\n",
    "#         f.write(\"%s\\n\" % line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Tree Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_list = []\n",
    "obj_len = 0\n",
    "for tree in trees:\n",
    "    if tree == 'phecode':\n",
    "        obj_list += [(i, tree) for i in trees[tree].text.keys()] * 70\n",
    "        obj_len += len(trees[tree]) * 100\n",
    "    elif tree == 'cpt':\n",
    "        obj_list += [(i, tree) for i in trees[tree].text.keys()] * 10\n",
    "        obj_len += len(trees[tree]) * 15\n",
    "    else:\n",
    "        obj_list += [(i, tree) for i in trees[tree].text.keys()]\n",
    "        obj_len += len(trees[tree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8296b6011e489387a1fc8f327509d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=609854.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 5\n",
    "\n",
    "tree_pairs = {}\n",
    "tree_terms = {}\n",
    "for tree in trees:\n",
    "    tree_pairs[tree] = []\n",
    "    tree_terms[tree] = [i for j in list(trees[tree].text.values()) for i in j]\n",
    "\n",
    "\n",
    "for anchor_id, tree in tqdm(obj_list):\n",
    "\n",
    "    if anchor_id not in trees[tree].text:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    samples = {}\n",
    "    samples_text = {}\n",
    "    for i in range(3):\n",
    "        samples[i] = []\n",
    "        samples_text[i] = []\n",
    "    \n",
    "    \n",
    "\n",
    "    if tree == 'phecode':\n",
    "        if \".\" not in anchor_id:\n",
    "            level = 3\n",
    "        else:\n",
    "            level = 3 - len(anchor_id.split(\".\")[1])\n",
    "            \n",
    "        samples[level - 1] += [i for i in trees[tree].children[anchor_id]]\n",
    "        \n",
    "        if anchor_id in trees[tree].parent:\n",
    "            parent = trees[tree].parent[anchor_id]\n",
    "            samples[level] += [parent]\n",
    "            samples[level] += [i for i in trees[tree].children[parent] if i != anchor_id]\n",
    "        \n",
    "    else:\n",
    "        samples[1] += [i for i in trees[tree].children[anchor_id]]\n",
    "        if anchor_id in trees[tree].parent:\n",
    "            parent = trees[tree].parent[anchor_id]\n",
    "            samples[2] += [parent]\n",
    "            samples[1] += [i for i in trees[tree].children[parent] if i != anchor_id]\n",
    "\n",
    "    samples[0] += [anchor_id]\n",
    "    assert len(samples[0]) == 1\n",
    "\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in samples[i]:\n",
    "            if j in trees[tree].text:\n",
    "                samples_text[i] += trees[tree].text[j]\n",
    "\n",
    "    \n",
    "    for i in samples_text:\n",
    "        if len(samples_text[i]) > 2*MAX_SAMPLES:\n",
    "            samples_text[i] = random.sample(samples_text[i], 2*MAX_SAMPLES)\n",
    "                \n",
    "    \n",
    "    pairs = list(itertools.combinations(samples_text[0], 2))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(0) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        tree_pairs[tree].append(line)    \n",
    "    \n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        pairs = list(itertools.product(samples_text[0], samples_text[i]))\n",
    "        if len(pairs) > MAX_SAMPLES:\n",
    "            pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "        for p in pairs:\n",
    "            line = str(i) + \"||\" + p[0] + \"||\" + p[1]\n",
    "            tree_pairs[tree].append(line)    \n",
    "\n",
    "            \n",
    "    random_samples = random.sample(tree_terms[tree], 2*MAX_SAMPLES)\n",
    "    pairs = list(itertools.product(samples_text[0], random_samples))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(3) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        tree_pairs[tree].append(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt 1219150\n",
      "loinc 1540454\n",
      "phecode 1607130\n",
      "rxnorm 1860910\n"
     ]
    }
   ],
   "source": [
    "for tree in tree_pairs:\n",
    "        print(tree, len(tree_pairs[tree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt 4751900\n",
      "loinc 4948254\n",
      "phecode 5924240\n",
      "rxnorm 5771353\n"
     ]
    }
   ],
   "source": [
    "for tree in tree_pairs:\n",
    "        print(tree, len(tree_pairs[tree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt 1219150\n",
      "loinc 1540454\n",
      "phecode 1394890\n",
      "rxnorm 1860910\n"
     ]
    }
   ],
   "source": [
    "for tree in tree_pairs:\n",
    "    with open('./training_files/' + tree + '.txt', 'w', encoding=\"utf-8\") as f:\n",
    "        for line in tree_pairs[tree]:\n",
    "            f.write(\"%s\\n\" % line)\n",
    "        print(tree, len(tree_pairs[tree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Phecode eval terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpt\n",
      "loinc\n",
      "phecode\n",
      "rxnorm\n"
     ]
    }
   ],
   "source": [
    "TREE_DIR = Path(\"D:/Projects/CODER/Hierarchical-CODER/data/cleaned/all\")\n",
    "\n",
    "TREE_SUBDIRS = [f for f in TREE_DIR.iterdir() if f.is_dir()]\n",
    "trees = {}\n",
    "for tree_subdir in TREE_SUBDIRS:\n",
    "    print(tree_subdir.name)\n",
    "    trees[tree_subdir.name] = TREE(tree_subdir/\"hierarchy.csv\", tree_subdir/\"code2string.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "with open('./phecode_holdout_set.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f82eb2a531b43cab09f6bf714b8f83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "eval_tree_codes = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    eval_tree_codes.append(lst[0])\n",
    "\n",
    "all_eval_phecodes = []\n",
    "all_eval_phecodes_text = {}\n",
    "for phecode in trees[\"phecode\"].text:\n",
    "    if phecode.split(\".\")[0] in eval_phecodes:\n",
    "        all_eval_phecodes.append(phecode)\n",
    "        all_eval_phecodes_text[phecode] = trees[\"phecode\"].text[phecode]\n",
    "\n",
    "print(len(all_eval_phecodes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3f353c2b904157ac23396f24d88122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=322.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 5\n",
    "\n",
    "phecode_pairs = []\n",
    "phecode_terms = [i for j in list(all_eval_phecodes_text.values()) for i in j]\n",
    "\n",
    "\n",
    "for anchor_id in tqdm(all_eval_phecodes):\n",
    "\n",
    "    assert anchor_id in all_eval_phecodes_text\n",
    "\n",
    "\n",
    "    samples = {}\n",
    "    samples_text = {}\n",
    "    for i in range(3):\n",
    "        samples[i] = []\n",
    "        samples_text[i] = []\n",
    "    \n",
    "    \n",
    "\n",
    "    if \".\" not in anchor_id:\n",
    "        level = 3\n",
    "    else:\n",
    "        level = 3 - len(anchor_id.split(\".\")[1])\n",
    "\n",
    "    samples[level - 1] += [i for i in trees[\"phecode\"].children[anchor_id]]\n",
    "\n",
    "    if anchor_id in trees[\"phecode\"].parent:\n",
    "        parent = trees[\"phecode\"].parent[anchor_id]\n",
    "        samples[level] += [parent]\n",
    "        samples[level] += [i for i in trees[\"phecode\"].children[parent] if i != anchor_id]\n",
    "        \n",
    "        \n",
    "    samples[0] += [anchor_id]\n",
    "    assert len(samples[0]) == 1\n",
    "\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in samples[i]:\n",
    "            if j in all_eval_phecodes_text:\n",
    "                samples_text[i] += all_eval_phecodes_text[j]\n",
    "\n",
    "    \n",
    "    for i in samples_text:\n",
    "        if len(samples_text[i]) > 2*MAX_SAMPLES:\n",
    "            samples_text[i] = random.sample(samples_text[i], 2*MAX_SAMPLES)\n",
    "                \n",
    "    \n",
    "    pairs = list(itertools.combinations(samples_text[0], 2))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(0) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        phecode_pairs.append(line)    \n",
    "    \n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        pairs = list(itertools.product(samples_text[0], samples_text[i]))\n",
    "        if len(pairs) > MAX_SAMPLES:\n",
    "            pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "        for p in pairs:\n",
    "            line = str(i) + \"||\" + p[0] + \"||\" + p[1]\n",
    "            phecode_pairs.append(line)    \n",
    "\n",
    "            \n",
    "    random_samples = random.sample(phecode_terms, 2*MAX_SAMPLES)\n",
    "    pairs = list(itertools.product(samples_text[0], random_samples))\n",
    "    if len(pairs) > MAX_SAMPLES:\n",
    "        pairs = random.sample(pairs, MAX_SAMPLES)\n",
    "    for p in pairs:\n",
    "        line = str(3) + \"||\" + p[0] + \"||\" + p[1]\n",
    "        phecode_pairs.append(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4325\n"
     ]
    }
   ],
   "source": [
    "# with open('../../sapbert_hierarchical_eval/data/phecode_eval.txt', 'w', encoding=\"utf-8\") as f:\n",
    "#     for line in phecode_pairs:\n",
    "#         f.write(\"%s\\n\" % line)\n",
    "#     print(len(phecode_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CUI-CUI eval pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f810f4b052408183b5019763243c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10541661.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "umls_dict = {} # constrauct cui to list of name dict, again\n",
    "for line in tqdm(cleaned_do_dup):\n",
    "    cui, name = line.split(\"||\")\n",
    "    if cui in umls_dict:\n",
    "        umls_dict[cui].append(name)\n",
    "    else:\n",
    "        umls_dict[cui] = [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "with open('./cui_cui_holdout_set.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ac5cd8157542bbb14200e6ba23c1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cui_pairs = []\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    cui_pairs.append([lst[0], lst[2], lst[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51da09fae4dc4ae38f3c1526778092cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132f47500e3841f082a092a25441f59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cui_cui_pairs = []\n",
    "cui_set = set()\n",
    "for l in tqdm(lines):\n",
    "    lst = l.rstrip(\"\\n\").split(\",\")\n",
    "    if lst[0] in umls_dict and lst[2] in umls_dict:\n",
    "        line = random.sample(umls_dict[lst[0]], 1)[0] + \"||\" + random.sample(umls_dict[lst[2]], 1)[0] + \"||\" + lst[3]\n",
    "        cui_cui_pairs.append(line)\n",
    "        cui_set.add(lst[0])\n",
    "        cui_set.add(lst[2])\n",
    "\n",
    "        \n",
    "random_cuis = random.choices(list(cui_set), k=2*5000)\n",
    "for i in tqdm(range(5000)):\n",
    "    cui1, cui2 = random_cuis[2*i:2*(i + 1)]\n",
    "    if cui1 != cui2:\n",
    "        line = random.sample(umls_dict[cui1], 1)[0] + \"||\" + random.sample(umls_dict[cui2], 1)[0] + \"||\" + \"random\"\n",
    "        cui_cui_pairs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "x = Counter([x.split(\"||\")[2] for x in cui_cui_pairs])\n",
    "common_relations = []\n",
    "for i in x:\n",
    "    if len(i) > 0 and x[i] > 2000:\n",
    "        common_relations.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_cui_pairs_dict = {}\n",
    "for line in cui_cui_pairs:\n",
    "    relation = line.split(\"||\")[2]\n",
    "    if relation in common_relations:\n",
    "        if relation in cui_cui_pairs_dict:\n",
    "            cui_cui_pairs_dict[relation].append(line)\n",
    "        else:\n",
    "            cui_cui_pairs_dict[relation] = [line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classified_as 5034\n",
      "classified_as 1000\n",
      "translation_of 7493\n",
      "translation_of 1000\n",
      "isa 11443\n",
      "isa 1000\n",
      "inverse_isa 11219\n",
      "inverse_isa 1000\n",
      "mapped_from 3523\n",
      "mapped_from 1000\n",
      "has_member 5192\n",
      "has_member 1000\n",
      "member_of 5198\n",
      "member_of 1000\n",
      "has_translation 7401\n",
      "has_translation 1000\n",
      "expanded_form_of 2003\n",
      "expanded_form_of 1000\n",
      "mapped_to 3416\n",
      "mapped_to 1000\n",
      "has_inactive_ingredient 6600\n",
      "has_inactive_ingredient 1000\n",
      "inactive_ingredient_of 6642\n",
      "inactive_ingredient_of 1000\n",
      "classifies 5072\n",
      "classifies 1000\n",
      "has_expanded_form 2068\n",
      "has_expanded_form 1000\n",
      "random 5000\n",
      "random 5000\n"
     ]
    }
   ],
   "source": [
    "for relation in cui_cui_pairs_dict:\n",
    "    if relation != \"random\":\n",
    "        cui_cui_pairs_dict[relation] = random.sample(cui_cui_pairs_dict[relation], 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87304\n"
     ]
    }
   ],
   "source": [
    "# with open('../../sapbert_hierarchical_eval/data/cui_cui_eval.txt', 'w', encoding=\"utf-8\") as f:\n",
    "#     for line in cui_cui_pairs_filtered:\n",
    "#         f.write(\"%s\\n\" % line)\n",
    "#     print(len(cui_cui_pairs_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
